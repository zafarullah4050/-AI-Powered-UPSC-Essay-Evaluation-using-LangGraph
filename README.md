# -AI-Powered-UPSC-Essay-Evaluation-using-LangGraph
ðŸ“Œ Overview

This project demonstrates how to use LangGraph to build an AI workflow for UPSC-style answer evaluation.
The workflow is designed as a graph, where each step evaluates different aspects of an answer (language, analysis, thought process), and finally produces a combined evaluation.

âš¡ Workflow Design
Nodes in the Graph

Evaluate Language â†’ Checks grammar, clarity, and structure of the answer.

Evaluate Analysis â†’ Evaluates depth, factual correctness, and arguments.

Evaluate Thought Process â†’ Measures originality, coherence, and flow of ideas.

Final Evaluation â†’ Combines all three evaluations into a single report.

Graph Flow
START â†’ evaluate_language â†’ final_evaluation
START â†’ evaluate_analysis â†’ final_evaluation
START â†’ evaluate_thought â†’ final_evaluation
final_evaluation â†’ END

ðŸ”§ Tech Stack

Python

LangGraph (stateful agentic AI workflows)

LangChain (LLM integration)

ðŸš€ How to Run

Clone this repository

Install dependencies:

pip install langgraph langchain


Run the notebook:

jupyter notebook UPSC_Workflow.ipynb

ðŸŽ¯ Use Case

This project can be extended for:

Academic answer evaluation

Essay scoring

Interview preparation feedback

Automated report generation

ðŸŒŸ Future Scope

Add memory to track multiple answers per candidate

Use RAG (Retrieval-Augmented Generation) for fact-checking answers

Deploy as a web app using Streamlit or FastAPI
